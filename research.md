<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">

# currently...
![Illustration of robot demo](/assets/clutter_demo.png)
- **Task-Informed Robotic Manipulation** ~ _Improbable AI Group (MIT CSAIL)_
    
    I'm collaborating with Anthony Simeonov to explore robotic manipulation of novel, cluttered objects conditioned on manipulation task. In the way that you wouldn't grab a mug by its rim if you wanted to flip it upside down, we want to generate grasps that depend on what the robot intends to do with an object.
    
    Current questions: Can we take task/motion planning into account when generating grasps? What are ways to allow for subgoal search given an ultimate goal and potentially unfavorable initial object configurations?
    
    Using: PyTorch, ROS, PointNet++ architecture, GraspNet architecture, CVAEs, Docker, PyBullet, RViz

<img src='assets/hsa_screencap.jpg' alt='Screenshot of HSA' width='300'>

- **Computational Design of Fluidic Sensors** ~ _Distributed Robotics Lab (MIT CSAIL)_
    
    I'm working with Lilly Chin to create computational design tools and pipelines for fluidic and tactile sensor prototyping. We're focusing on adding sensor capability to her work on handed shearing auxetics (HSAs), as well as iterating on the team's tactile sensors for soft robotic grasping.
    
    Using: Grasshopper, Rhino, Rhinoscript, Carbon3D printer, basic electronics

# previously...

- **Venous Materials** ~ _Tangible Media Group (MIT Media Lab)_
    
    I worked with postdoctoral student Hila Mor and faculty advisor Hiroshi Ishii to help develop a more user intuitive interface for Venous Materials: physical fluidic circuits and veins as pressure and deformation sensors. Prototyped a method to print the designs using a novel type of nonplanar 3D printing, as well as streamlining the user interface of the design tool and prototyping different types of logic gate primitives.
    
    Used: Grasshopper3D, Rhino
